{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import lbforaging\n",
    "import decision_transformer.models.decision_transformer\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "import rware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"hopper-medium-v2\"\n",
    "\n",
    "dataset_path = f'data/{env_name}.pkl'\n",
    "with open(dataset_path, 'rb') as f:\n",
    "    trajectories_hopper = pickle.load(f)\n",
    "    \n",
    "states, traj_lens, returns = [], [], []\n",
    "for path in trajectories2:\n",
    "    states.append(path['states'])\n",
    "\n",
    "# used for input normalization\n",
    "states = np.concatenate(states, axis=0)\n",
    "state_mean_global, state_std_global = np.mean(states, axis=0), np.std(states, axis=0) + 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = \"/work3/s174437/Blankuca/decision-transformer/dataset/saved_models/model_cooperative.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zhome/09/9/127654/anaconda3/envs/decision-transformer-gym/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "behavior = \"cooperative\"\n",
    "env = gym.make(\"Foraging-8x8-2p-3f-v2\")\n",
    "state_dim = env.observation_space[0].shape[0] * 2\n",
    "act_dim = 1\n",
    "device='cpu'\n",
    "model = torch.load(path_to_model, map_location=torch.device('cpu'))\n",
    "max_ep_len=10000\n",
    "scale=1\n",
    "target_return=torch.Tensor([0.5,0.5], device=device)\n",
    "mode='normal'\n",
    "state_mean=state_mean_global\n",
    "state_std=state_std_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19177/3566384189.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target_return = torch.tensor(ep_return, device=device, dtype=torch.float32).reshape(num_agents,1, 1)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.to(device=device)\n",
    "\n",
    "num_agents = env.n_agents\n",
    "\n",
    "state_mean = torch.from_numpy(state_mean).to(device=device)\n",
    "state_std = torch.from_numpy(state_std).to(device=device)\n",
    "\n",
    "env_global = env.reset()\n",
    "states = env_global\n",
    "state = np.concatenate(states)\n",
    "if mode == 'noise':\n",
    "    state = state + np.random.normal(0, 0.1, size=state.shape)\n",
    "\n",
    "# we keep all the histories on the device\n",
    "# note that the latest action and reward will be \"padding\"\n",
    "states = torch.from_numpy(state).reshape(1, state_dim).to(device=device, dtype=torch.float32)\n",
    "actions = torch.zeros((0, act_dim), device=device, dtype=torch.float32)\n",
    "rewards = torch.zeros(num_agents, 0, device=device, dtype=torch.float32)\n",
    "\n",
    "ep_return = target_return\n",
    "target_return = torch.tensor(ep_return, device=device, dtype=torch.float32).reshape(num_agents,1, 1)\n",
    "timesteps = torch.tensor(0, device=device, dtype=torch.long).reshape(1, 1)\n",
    "\n",
    "sim_states = []\n",
    "\n",
    "avail_actions = list(range(len(env.action_set) + 1))\n",
    "combinations = list(product(avail_actions, repeat=num_agents))\n",
    "enc_action_to_actions = {i:comb for i,comb in enumerate(combinations)}\n",
    "actions_to_enc_actions = {comb:i for i,comb in enumerate(combinations)}\n",
    "\n",
    "episode_return, episode_length = torch.zeros(num_agents, device=device, dtype=torch.float32), 0\n",
    "\n",
    "record_actions = []\n",
    "for t in range(max_ep_len):\n",
    "\n",
    "    # add padding\n",
    "    actions = torch.cat([actions, torch.zeros((1, act_dim), device=device)], dim=0)\n",
    "    rewards = torch.cat([rewards, torch.zeros(num_agents,1, device=device)], dim=1)\n",
    "\n",
    "\n",
    "    action = model.get_action(\n",
    "        (states.to(dtype=torch.float32) - state_mean) / state_std,\n",
    "        actions.to(dtype=torch.float32),\n",
    "        rewards.to(dtype=torch.float32),\n",
    "        target_return.to(dtype=torch.float32),\n",
    "        timesteps.to(dtype=torch.long),\n",
    "    )\n",
    "    action = action.argmax(dim=1).tolist()\n",
    "    record_actions.append(action)\n",
    "    actions[-1] = actions_to_enc_actions[tuple(action)]\n",
    "\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    state = np.concatenate(state)\n",
    "\n",
    "    reward = torch.FloatTensor(reward).to(device=device)\n",
    "    episode_return = episode_return.add(reward)\n",
    "    episode_length += 1\n",
    "    \n",
    "    done = all(done)\n",
    "\n",
    "    cur_state = torch.from_numpy(state).to(device=device).reshape(1, state_dim)\n",
    "    states = torch.cat([states, cur_state], dim=0)\n",
    "    rewards[:,-1] = reward\n",
    "\n",
    "    if mode != 'delayed':\n",
    "        pred_return = target_return[:,0,-1].sub(reward/scale)\n",
    "    else:\n",
    "        pred_return = target_return[:,0,-1]\n",
    "    target_return = torch.cat(\n",
    "        [target_return, pred_return.reshape(-1, 1, 1)], dim=1)\n",
    "    timesteps = torch.cat(\n",
    "        [timesteps,\n",
    "            torch.ones((1, 1), device=device, dtype=torch.long) * (t+1)], dim=1)\n",
    "\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_state(env, step=0, info=\"\"):\n",
    "    plt.figure(3, figsize=(10,10))\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    #plt.title(\"%s | Step: %d %s\" % (\"env\",step, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    #display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'record_actions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/work3/s174437/Blankuca/decision-transformer/gym/see_replays.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blogin2.gbar.dtu.dk/work3/s174437/Blankuca/decision-transformer/gym/see_replays.ipynb#ch0000006vscode-remote?line=2'>3</a>\u001b[0m \u001b[39m#prev_screen = env.render(mode='rgb_array')\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blogin2.gbar.dtu.dk/work3/s174437/Blankuca/decision-transformer/gym/see_replays.ipynb#ch0000006vscode-remote?line=3'>4</a>\u001b[0m \u001b[39m#plt.imshow(prev_screen)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blogin2.gbar.dtu.dk/work3/s174437/Blankuca/decision-transformer/gym/see_replays.ipynb#ch0000006vscode-remote?line=4'>5</a>\u001b[0m \u001b[39m#env = env_global\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blogin2.gbar.dtu.dk/work3/s174437/Blankuca/decision-transformer/gym/see_replays.ipynb#ch0000006vscode-remote?line=6'>7</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blogin2.gbar.dtu.dk/work3/s174437/Blankuca/decision-transformer/gym/see_replays.ipynb#ch0000006vscode-remote?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m action \u001b[39min\u001b[39;00m record_actions:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blogin2.gbar.dtu.dk/work3/s174437/Blankuca/decision-transformer/gym/see_replays.ipynb#ch0000006vscode-remote?line=8'>9</a>\u001b[0m   i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin2.gbar.dtu.dk/work3/s174437/Blankuca/decision-transformer/gym/see_replays.ipynb#ch0000006vscode-remote?line=9'>10</a>\u001b[0m   obs, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'record_actions' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#prev_screen = env.render(mode='rgb_array')\n",
    "#plt.imshow(prev_screen)\n",
    "env = env_global\n",
    "\n",
    "i = 0\n",
    "for action in record_actions:\n",
    "  i += 1\n",
    "  obs, reward, done, info = env.step(action)\n",
    "  show_state(env, step=i)\n",
    "  #screen = env.render(mode='rgb_array')\n",
    "  \n",
    "  #plt.imshow(screen)\n",
    "  #ipythondisplay.clear_output(wait=True)\n",
    "  #ipythondisplay.display(plt.gcf())\n",
    "\n",
    "  if done:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import lbforaging\n",
    "import decision_transformer.models.decision_transformer\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "import rware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "layout = \"\"\"\n",
    ".......\n",
    "xxxxxxx\n",
    ".......\n",
    "xxx.xxx\n",
    "...x...\n",
    ".g...g.\n",
    "\"\"\"\n",
    "\n",
    "layout = \"\"\"\n",
    ".xxx.\n",
    ".g.g.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "env = gym.make(\"rware-tiny-2ag-v1\", layout=layout)\n",
    "env.reset()\n",
    "show_state(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = [0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 = nothing\n",
    "1 = move foward\n",
    "2 = rotate counter-clockwise\n",
    "3 = rotate clock-wise\n",
    "4 = load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0, 1.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs, r, _, _ = env.step([1,4])\n",
    "show_state(env)\n",
    "rewards = [r[0]+rewards[0], r[1]+rewards[1]]\n",
    "print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 7)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.request_queue[0].x, env.request_queue[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.request_queue[1].x, env.request_queue[1].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ 5., 10.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
       "          0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          1.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       "  array([0., 8., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0.], dtype=float32)),\n",
       " [0.0, 0.0],\n",
       " [False, False],\n",
       " {})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step([0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7., 2., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 9., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<rware.warehouse.Shelf at 0x7f30d1978ca0>,\n",
       " <rware.warehouse.Shelf at 0x7f30d1978be0>]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.request_queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 7), (2, 6)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(q.x,q.y) for q in env.request_queue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.33333333, 0.        ,\n",
       "       0.        , 0.33333333, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.33333333])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories[3][\"rewards\"].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trajectories[2][\"rewards\"].sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True, False,  True])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories2[6][\"states\"][0] == trajectories2[6][\"states\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.,  6.,  1.,  5.,  6.,  1.,  3.,  6.,  1.,  1.,\n",
       "         3.,  1.,  1.,  1.,  1.,  1.,  6.,  1.,  5.,  6.,  1.,  1.,  3.,\n",
       "         1.,  3.,  6.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.,  6.,  1.,  5.,  6.,  1.,  3.,  5.,  1.,  1.,\n",
       "         2.,  1.,  1.,  1.,  1.,  1.,  6.,  1.,  5.,  6.,  1.,  1.,  2.,\n",
       "         1.,  3.,  5.,  1.],\n",
       "       [ 1.,  6.,  1.,  5.,  6.,  1., -1., -1.,  0.,  3.,  4.,  1.,  1.,\n",
       "         2.,  1.,  1.,  6.,  1.,  5.,  6.,  1., -1., -1.,  0.,  1.,  2.,\n",
       "         1.,  3.,  4.,  1.],\n",
       "       [ 1.,  6.,  1.,  5.,  6.,  1., -1., -1.,  0.,  3.,  4.,  1.,  1.,\n",
       "         3.,  1.,  1.,  6.,  1.,  5.,  6.,  1., -1., -1.,  0.,  1.,  3.,\n",
       "         1.,  3.,  4.,  1.],\n",
       "       [ 1.,  6.,  1.,  5.,  6.,  1., -1., -1.,  0.,  3.,  5.,  1.,  1.,\n",
       "         4.,  1.,  1.,  6.,  1.,  5.,  6.,  1., -1., -1.,  0.,  1.,  4.,\n",
       "         1.,  3.,  5.,  1.],\n",
       "       [ 1.,  6.,  1.,  5.,  6.,  1., -1., -1.,  0.,  3.,  6.,  1.,  1.,\n",
       "         5.,  1.,  1.,  6.,  1.,  5.,  6.,  1., -1., -1.,  0.,  1.,  5.,\n",
       "         1.,  3.,  6.,  1.],\n",
       "       [ 1.,  6.,  1.,  5.,  6.,  1., -1., -1.,  0.,  2.,  6.,  1.,  1.,\n",
       "         5.,  1.,  1.,  6.,  1.,  5.,  6.,  1., -1., -1.,  0.,  1.,  5.,\n",
       "         1.,  2.,  6.,  1.],\n",
       "       [ 5.,  6.,  1., -1., -1.,  0., -1., -1.,  0.,  2.,  6.,  1.,  1.,\n",
       "         5.,  1.,  5.,  6.,  1., -1., -1.,  0., -1., -1.,  0.,  1.,  5.,\n",
       "         1.,  2.,  6.,  1.],\n",
       "       [ 5.,  6.,  1., -1., -1.,  0., -1., -1.,  0.,  3.,  6.,  1.,  2.,\n",
       "         5.,  1.,  5.,  6.,  1., -1., -1.,  0., -1., -1.,  0.,  2.,  5.,\n",
       "         1.,  3.,  6.,  1.],\n",
       "       [ 5.,  6.,  1., -1., -1.,  0., -1., -1.,  0.,  4.,  6.,  1.,  3.,\n",
       "         5.,  1.,  5.,  6.,  1., -1., -1.,  0., -1., -1.,  0.,  3.,  5.,\n",
       "         1.,  4.,  6.,  1.],\n",
       "       [-1., -1.,  0., -1., -1.,  0., -1., -1.,  0.,  4.,  6.,  1.,  4.,\n",
       "         5.,  1., -1., -1.,  0., -1., -1.,  0., -1., -1.,  0.,  4.,  5.,\n",
       "         1.,  4.,  6.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories2[6][\"states\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trajectories2[6][\"actions\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trajectories[4][\"rewards\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 2, 5, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 5, 3, 3, 5],\n",
       "       [3, 3, 5, 5, 2, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 3, 2]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories[4][\"actions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2092.024999999978"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([t[\"rewards\"].sum(axis=0)[-1] for t in trajectories2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories2[6][\"rewards\"].sum(axis=0)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.33333333, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.33333333, 0.        , 0.        ,\n",
       "       0.33333333])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories2[6][\"rewards\"].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories_hopper[0][\"observations\"][1] == trajectories_hopper[0][\"next_observations\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['observations', 'next_observations', 'actions', 'rewards', 'terminals'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories_hopper[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a391b674f748329d9ab69a23d1142ccf13ef3980195c2e65c51d7033fef9ace8"
  },
  "kernelspec": {
   "display_name": "decision-transformer-gym",
   "language": "python",
   "name": "decision-transformer-gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
